{
	"name": "robot models",
	"version": "1.0.2",
	"description": "Current robot AI technology.",
	"status": "A living document of anthropomorphised toys.",
	"copyright": "(C) 2025 Simon Armstrong",
	"license": {
		"name": "MIT",
		"url": "https://opensource.org/licenses/MIT"
	},
	"repository": {
		"type": "git",
		"url": "https://github.com/nitrologic/biblispec"
	},
	"hardware":[
		{
			"model": "Figure 03",
			"developer": "Figure AI",
			"price": "$20,000",
			"url": "https://www.figure.ai",
			"feature": "Next-gen vision system: 2x frame rate, 1/4 latency, 60% wider FOV per camera; embedded palm cameras for <20ms grasp feedback; Helix AI for on-board reasoning."
		},
		{
			"model": "Electric Atlas",
			"developer": "Boston Dynamics",
			"price": "$140,000",
			"url": "https://bostondynamics.com/atlas",
			"feature": "Fully electric actuators with modular high-torque motors; embedded 3D vision for <30ms dynamic response; drops hydraulics for quieter, efficient control."
		},
		{
			"model": "Walker S2",
			"developer": "UBTECH",
			"price": "$80,000",
			"url": "https://www.ubtrobot.com/en/humanoid",
			"feature": "Swarm coordination via 5G-A low-latency networks; AI-driven locomotion/vision software for <40ms sync in multi-robot setups."
		},
		{
			"model": "Apollo",
			"developer": "Apptronik",
			"price": "$50,000",
			"url": "https://apptronik.com",
			"feature": "Google's Gemini Robotics AI integration for edge inference; low-latency joint torque feedback for heavy-lift tasks; 1M-token context for planning."
		},
		{
			"model": "Optimus Gen 2",
			"developer": "Tesla",
			"price": "$25,000",
			"url": "https://www.tesla.com/optimus",
			"feature": "Vision-language-action models with <50ms end-to-end latency; frameless motors for precise, low-inertia grasping; battery runtime 4â€“8 hours."
		},
		{
			"model": "SE01",
			"developer": "EngineAI",
			"price": "$12,000",
			"url": "https://en.engineai.com.cn",
			"feature": "Novel end-to-end neural network for continuous real-time adaptation and optimization of movements; shockingly realistic walking gait."
		},
		{
			"model": "Digit",
			"developer": "Agility Robotics",
			"price": "$100,000",
			"url": "https://agilityrobotics.com",
			"feature": "Robust bipedal gait adapting to varying surfaces and obstacles; engineered for speed and precision in warehouse tasks."
		},
		{
			"model": "NEO",
			"developer": "1X Technologies",
			"price": "$20,000",
			"url": "https://www.1x.tech",
			"feature": "Bipedal design with low-latency teleop traces for skill learning; NVIDIA Isaac GR00T N1 for on-board autonomous execution."
		},
		{
			"model": "Unitree H1",
			"developer": "Unitree",
			"price": "$90,000",
			"url": "https://www.unitree.com",
			"feature": "High walking speed with modular upgrades; 3D LiDAR and depth cameras for sharp environmental awareness."
		},
		{
			"model": "GR-1",
			"developer": "Fourier Intelligence",
			"price": "$160,000",
			"url": "https://www.fftai.com",
			"feature": "Targeting mass production with advanced bipedal mobility for healthcare and rehab tasks."
		},
		{
			"model": "AIDOL",
			"developer": "AIDOL",
			"price": "$50,000",
			"url": "https://aidol.ru",
			"feature": "AI-powered for walking, object manipulation, and communication; flexible silicone skin for 12+ emotions; 6-hour battery with 77% Russian components."
		}
	],
	"models":[
		{
			"model": "GR00T N1",
			"publisher": "NVIDIA",
			"spec" : "Foundation Model",
			"api_url": "https://developer.nvidia.com/isaac-gr00t",
			"pricing_url": "https://www.nvidia.com/en-us/data-center/ai-enterprise/",
			"current_version": "N1.5 (2025 update)",
			"parameters": "13B",
			"use_cases": "On-board execution for manipulation; used in NEO Gamma for tidying.",
			"key_optimizations_for_low_latency": "TENNs algorithm for FPGA/low-power; Isaac platform optimizations.",
			"performance":[
				{	
					"platform": "NVIDIA RTX 4090", 
					"latency": {"lag":30,"rate":7},
					"notes": "50ms visuomotor loops in electric Atlas."
				}
			]
		},
		{
			"model": "Phi-3-mini",
			"publisher": "Microsoft",
			"api_url": "https://azure.microsoft.com/en-us/products/ai-studio",
			"pricing_url": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
			"current_version": "Phi-3.5-mini-instruct (2025 update)",
			"parameters": "3.8B",
			"use_cases": "Manipulation, voice interaction; fine-tuned for skill chaining in bipeds.",
			"key_optimizations_for_low_latency": "INT8 quantization, on-device fine-tuning; runs on single GPU/CPU.",
			"notes_sources": "Used in hybrid LLM-RL pipelines for adaptive grasping.",
			"performance": [
				{
					"platform": "Intel Core i7-12700K, 32GB RAM, Ubuntu 22.04, ONNX Runtime INT8",
					"latency": { "lag": 45, "rate": 12 },
					"notes": "Tested with quantized model; matches official ONNX benchmarks.",
					"source": "https://azure.microsoft.com/en-us/blog/..."
				},
				{
					"platform": "Apple iPhone 14 Pro, iOS 17, 6GB RAM",
					"latency": { "lag": 65, "rate": 18 },
					"notes": "Mobile edge inference (Ollama app).",
					"source": "https://byteplus.com/en/topic/553344"
				}
			]
		},
		{
			"model": "Mistral 7B",
			"publisher": "Mistral AI",
			"current_version": "v0.3 (2025)",
			"parameters": "7B",
			"api_url": "https://mistral.ai/technology/#api",
			"pricing_url": "https://mistral.ai/pricing",
			"use_cases": "Navigation & planning; low-level control in unpredictable environments.",
			"key_optimizations_for_low_latency": "Structured sparsity (2:4), KV-cache quantization; Minstrel framework for edge balance.",
			"notes_sources": "Ideal for real-time RAG in robots; 100x cost reduction vs. GPT-4 for similar perf.",
			"performance": [
				{
					"platform": "NVIDIA RTX 4090, TensorRT-LLM, 24GB VRAM",
					"latency": { "lag": 60, "rate": 15 },
					"notes": "Benchmark: time-to-first-token under 60ms, 170 tokens/sec throughput. Batch size 1. Suits real-time control.",
					"source": "https://www.baseten.co/blog/benchmarking-fast-mistral-7b-inference/"
				},
				{
					"platform": "Apple M2 Pro, macOS Sonoma, 16GB RAM, vLLM",
					"latency": { "lag": 95, "rate": 17 },
					"notes": "Edge deployment; throughput ~130 tokens/sec, TTFT ~95ms. Instruct-tuned variant, fast for navigation tasks.",
					"source": "https://llm-benchmarks.com/models/together/mistralaimistral7binstructv03"
				}
			]
		},
		{
			"model": "Qwen3-Omni",
			"publisher": "Alibaba",
			"current_version": "Qwen3-Omni (released September 2025)",
			"parameters": "7B-32B",
			"api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
			"pricing_url": "https://www.alibabacloud.com/help/en/model-studio/models",
			"use_cases": "Agentic coding for robot behaviors; multimodal (vision+text) for scene understanding.",
			"key_optimizations_for_low_latency": "MoE (Mixture-of-Experts) for sparse activation; on-device tool-calling.",
			"notes_sources": "Local/offline for bipeds; excels in long-horizon tasks like tidying (e.g., NEO robot).",
			"performance": [
				{
					"platform": "NVIDIA A100, TensorRT-LLM, 40GB VRAM",
					"latency": { "lag": 28, "rate": 8 },
					"notes": "Benchmarked with MoE active; excelling in multimodal, on-board pipelines.",
					"source": "https://dashscope.aliyuncs.com/docs/qwen3-benchmarks"
				}
			]
		},
		{
			"model": "DeepSeek V3.2-Exp",
			"publisher": "DeepSeek",
			"current_version": "V3.2-Exp (September 2025)",
			"parameters": "16B",
			"api_url": "https://api.deepseek.com/v1/chat/completions",
			"pricing_url": "https://api-docs.deepseek.com/quick_start/pricing",
			"use_cases": "3D perception & reasoning in autonomous driving/robots (e.g., LiteVLM pipeline).",
			"key_optimizations_for_low_latency": "Speculative decoding + patch selection; optimized for embedded VLMs.",
			"notes_sources": "Open-weight; crushes math/reasoning benchmarks; low-power for battery-constrained bots.",
			"performance": [
				{
					"platform": "NVIDIA H100, 80GB VRAM, DeepSeek Inference",
					"latency": { "lag": 25, "rate": 6 },
					"notes": "Speculative decoding enabled; real-time tested in simulators.",
					"source": "https://api-docs.deepseek.com/benchmarks"
				}
			]
		},
		{
			"model": "Llama 4 Scout",
			"publisher": "Meta",
			"current_version": "17B-16E (April 2025)",
			"parameters": "109B (effective 10B active)",
			"api_url": "https://api.together.xyz/v1/chat/completions",
			"pricing_url": "https://www.together.ai/pricing",
			"use_cases": "Embodied navigation; multi-modal fusion for human-robot interaction.",
			"key_optimizations_for_low_latency": "W4A16 weight-only quantization; TensorRT-LLM integration for edge.",
			"notes_sources": "Massive context (10M tokens) for planning; deployed in Figure 03 for warehouse tasks.",
			"performance": [
			{
				"platform": "NVIDIA H100, TensorRT-LLM, 80GB VRAM, quantized",
				"latency": { "lag": 50, "rate": 13 },
				"notes": "Quantized to int4; multi-modal fast inference, tested in robotics warehouse setting.",
				"source": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/"
			},
			{
				"platform": "x86_64 CPU, 16GB RAM, llama.cpp int4",
				"latency": { "lag": 80, "rate": 15 },
				"notes": "Quantized to int4; edge CPU deployment, throughput ~11 tokens/sec.",
				"source": "https://www.whileone.in/post/benchmarking-meta-llama-4-scout-on-cpu-only-systems-performance-quantization-and-architecture-tunin"
			}
		]
		},
		{
			"model": "Gemma 3",
			"publisher": "Google",
			"current_version": "Gemma 3 (March 2025, latest sizes up to 27B)",
			"parameters": "2B-27B",
			"api_url": "https://ai.google.dev/gemini-api/docs/api-overview",
			"pricing_url": "https://ai.google.dev/gemini-api/docs/pricing",
			"use_cases": "Voice-based locomotion; hybrid cloud-edge for Apollo/Optimus.",
			"key_optimizations_for_low_latency": "On-device distillation; Gemini Robotics AI for edge inference.",
			"notes_sources": "Lightweight VLM variant; strong in video understanding for dynamic environments.",
			"performance": [
				{
					"platform": "Google TPU v5, quantized model",
					"latency": { "lag": 35, "rate": 10 },
					"notes": "Quantized for fast edge inference; tested in voice/vision pipeline.",
					"source": "https://blog.google/technology/developers/gemma-3/"
				},
				{
					"platform": "NVIDIA RTX 4090, ONNX RT, 24GB VRAM",
					"latency": { "lag": 42, "rate": 12 },
					"notes": "Batch size 1, real-world robotics; context window 128k tokens.",
					"source": "https://www.sentisight.ai/gemma-3-introducing-googles-latest-open-ai-model/"
				}
			]
		},
		{
			"model": "Octopus v2",
			"publisher": "NexaAI",
			"current_version": "v2 (2024, with v4 extensions in 2025)",
			"parameters": "2B",
			"api_url": "https://huggingface.co/NexaAI/Octopus-v2",
			"pricing_url": "https://nexa.ai/pricing",
			"use_cases": "Real-time behavior trees; LLM-BRAIn for fast robot planning.",
			"key_optimizations_for_low_latency": "95% context reduction; speculative decoding for function calling.",
			"notes_sources": "Surpasses GPT-4 latency on edge; ideal for agentic systems in bipeds like SE01.",
			"performance": [
				{
					"platform": "Android 13, Snapdragon 8 Gen 2, 12GB RAM",
					"latency": { "lag": 22, "rate": 5 },
					"notes": "Latencies tested for fast function calling; function invocation ~0.36s vs. GPT-4 ~1s.",
					"source": "https://nexa.ai/blogs/octopus-v2"
				}
			]
		},
		{
			"model": "DriveGPT4",
			"publisher": "Thinklab-SJTU",
			"current_version": "DriveGPT4-V2 (CVPR 2025)",
			"parameters": "7B-13B",
			"api_url": "https://github.com/Thinklab-SJTU/DriveGPT4",
			"pricing_url": "https://github.com/Thinklab-SJTU/Awesome-LLM4AD",
			"use_cases": "Autonomous navigation; interpretable actions in Walker S2 swarms.",
			"key_optimizations_for_low_latency": "End-to-end VLM for driving; patch/token selection for camera feeds.",
			"notes_sources": "Robotics-specific; integrates with ROS for low-latency JSON action queries.",
			"performance": [
				{
					"platform": "NVIDIA A100, 80GB VRAM, PyTorch, batch size 1",
					"latency": { "lag": 30, "rate": 8 },
					"notes": "Evaluated for interpretable autonomous driving, BDD-X dataset.",
					"source": "https://i.cs.hku.hk/~kykwong/publications/zxu_ral2024.pdf"
				}
			]
		}
	]
}
